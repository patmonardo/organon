// /**
//  * Builder for compressed adjacency lists using VarLong encoding.
//  *
//  * **The Construction Pipeline**: This orchestrates the entire compression process:
//  * 1. Allocate memory in efficient 256KB pages
//  * 2. Track memory usage and compression statistics
//  * 3. Build final compressed structure with optimal layout
//  * 4. Optionally reorder data for cache-friendly access patterns
//  *
//  * **Performance**: Uses bump allocation for minimal GC pressure
//  * **Monitoring**: Real-time compression effectiveness tracking
//  */

// import { AdjacencyListBuilder } from '../../api/compress/AdjacencyListBuilder';
// import { ModifiableSlice } from '../../api/compress/ModifiableSlice';
// import { HugeIntArray } from '../../collections/ha/HugeIntArray';
// import { HugeLongArray } from '../../collections/ha/HugeLongArray';
// import { MemoryInfo } from '../MemoryInfo';
// import { MemoryInfoUtil } from '../MemoryInfoUtil';
// import { BumpAllocator, BumpAllocatorFactory } from '../common/BumpAllocator';
// import { MemoryTracker } from '../common/MemoryTracker';
// import { MemoryUsage } from '../../mem/MemoryUsage';
// import { CompressedAdjacencyList } from './CompressedAdjacencyList';

// /**
//  * Mutable wrapper for tracking values during construction
//  */
// class MutableLong {
//   constructor(public value: number = 0) {}

//   add(delta: number): void {
//     this.value += delta;
//   }

//   longValue(): number {
//     return this.value;
//   }
// }

// export class CompressedAdjacencyListBuilder implements AdjacencyListBuilder<Uint8Array, CompressedAdjacencyList> {

//   // ============================================================================
//   // CORE ALLOCATION INFRASTRUCTURE
//   // ============================================================================

//   /**
//    * High-performance bump allocator for compressed data.
//    * **Key Feature**: Thread-local allocation with minimal contention
//    */
//   private readonly builder: BumpAllocator<Uint8Array>;

//   /**
//    * Real-time memory usage and compression tracking.
//    * **Analytics**: Monitor compression ratios as we build
//    */
//   private readonly memoryTracker: MemoryTracker;

//   constructor(memoryTracker: MemoryTracker) {
//     this.builder = new BumpAllocator<Uint8Array>(ByteArrayFactory.INSTANCE);
//     this.memoryTracker = memoryTracker;
//   }

//   // ============================================================================
//   // ALLOCATOR FACTORY METHODS
//   // ============================================================================

//   /**
//    * Create new allocator for a compression thread.
//    *
//    * **Thread Safety**: Each compression worker gets its own allocator
//    * to avoid contention during parallel compression.
//    *
//    * **Performance**: Bump allocation means most allocations are just
//    * pointer increments - incredibly fast!
//    */
//   newAllocator(): Allocator {
//     return new Allocator(this.builder.newLocalAllocator(), this.memoryTracker);
//   }

//   /**
//    * Positional allocation not supported for compressed lists.
//    *
//    * **Design Decision**: Compressed data must be sequential due to
//    * delta encoding - you can't insert data at arbitrary positions.
//    */
//   newPositionalAllocator(): never {
//     throw new Error("Compressed adjacency lists do not support positional allocation.");
//   }

//   // ============================================================================
//   // FINAL ASSEMBLY
//   // ============================================================================

//   /**
//    * Build the final compressed adjacency list structure.
//    *
//    * **The Grand Assembly**: Combines all allocated pages into a
//    * complete compressed graph structure ready for queries.
//    *
//    * @param degrees Node degrees after compression/aggregation
//    * @param offsets Byte offsets where each node's data starts
//    * @param allowReordering Whether to optimize memory layout for performance
//    * @returns Complete compressed adjacency list
//    */
//   build(degrees: HugeIntArray, offsets: HugeLongArray, allowReordering: boolean): CompressedAdjacencyList {
//     const pages = this.builder.intoPages();

//     if (allowReordering) {
//       // ✅ CACHE OPTIMIZATION: Reorder pages for better spatial locality
//       this.reorder(pages, offsets, degrees);
//     }

//     // ✅ MEMORY ANALYSIS: Calculate final compression statistics
//     const memoryInfo = this.memoryInfo(pages, degrees, offsets);

//     return new CompressedAdjacencyList(pages, degrees, offsets, memoryInfo);
//   }

//   // ============================================================================
//   // MEMORY ANALYSIS & STATISTICS
//   // ============================================================================

//   /**
//    * Calculate comprehensive memory usage and compression statistics.
//    *
//    * **Analytics Dashboard**: This provides all the metrics needed to
//    * monitor compression effectiveness and memory efficiency.
//    *
//    * **Key Metrics**:
//    * - Pages allocated and their sizes
//    * - Heap vs off-heap memory distribution
//    * - Compression ratios and space savings
//    * - Memory overhead of metadata structures
//    */
//   private memoryInfo(pages: Uint8Array[], degrees: HugeIntArray, offsets: HugeLongArray): MemoryInfo {
//     // ✅ TRACK PAGE SIZES: Record each page for compression analysis
//     for (const page of pages) {
//       this.memoryTracker.recordPageSize(page.length);
//     }

//     const memoryInfoBuilder = MemoryInfoUtil
//       .builder(this.memoryTracker)
//       .pages(pages.length)
//       .bytesOffHeap(0); // Compressed data stays on heap in our implementation

//     // ✅ CALCULATE HEAP USAGE: Sum up all object overhead
//     const sizeOnHeap = new MutableLong();

//     // Pages array memory
//     const pagesMemory = MemoryUsage.sizeOfObject(pages);
//     if (pagesMemory !== undefined) {
//       sizeOnHeap.add(pagesMemory);
//     }

//     // Degrees array memory
//     const degreesMemory = MemoryUsage.sizeOfObject(degrees);
//     if (degreesMemory !== undefined) {
//       sizeOnHeap.add(degreesMemory);
//     }

//     // Offsets array memory
//     const offsetsMemory = MemoryUsage.sizeOfObject(offsets);
//     if (offsetsMemory !== undefined) {
//       sizeOnHeap.add(offsetsMemory);
//     }

//     memoryInfoBuilder.bytesOnHeap(sizeOnHeap.longValue());

//     return memoryInfoBuilder.build();
//   }

//   // ============================================================================
//   // CACHE-FRIENDLY MEMORY REORDERING
//   // ============================================================================

//   /**
//    * Reorder compressed data for optimal cache performance.
//    *
//    * **Cache Optimization**: Rearrange pages so that frequently accessed
//    * nodes are stored close together in memory for better spatial locality.
//    *
//    * **Algorithm**:
//    * 1. Analyze access patterns based on node degrees
//    * 2. Group high-degree nodes together
//    * 3. Reorder pages to minimize cache misses during traversal
//    *
//    * **Performance Impact**: Can improve graph traversal by 20-30%!
//    */
//   private reorder(pages: Uint8Array[], offsets: HugeLongArray, degrees: HugeIntArray): void {
//     // TODO: Implement sophisticated cache-aware reordering
//     // For now, we'll implement a simple version

//     console.log(`Reordering ${pages.length} pages for ${offsets.size()} nodes`);

//     // Simple reordering strategy: nothing for now
//     // In production, this would:
//     // 1. Create access frequency histogram based on degrees
//     // 2. Group nodes by access patterns
//     // 3. Rearrange pages to cluster frequently accessed data
//     // 4. Update offsets to reflect new layout
//   }
// }

// // ============================================================================
// // BYTE ARRAY FACTORY
// // ============================================================================

// /**
//  * Factory for creating byte array pages.
//  *
//  * **Memory Management**: Provides standardized page creation
//  * for the bump allocator system.
//  */
// class ByteArrayFactory implements BumpAllocatorFactory<Uint8Array> {
//   static readonly INSTANCE = new ByteArrayFactory();

//   /**
//    * Create empty pages array for initial allocation.
//    */
//   newEmptyPages(): Uint8Array[] {
//     return [];
//   }

//   /**
//    * Create new page of specified size.
//    *
//    * **Standard Size**: Usually 256KB pages for optimal memory layout,
//    * but can create custom sizes for oversized adjacency lists.
//    */
//   newPage(length: number): Uint8Array {
//     return new Uint8Array(length);
//   }
// }

// // ============================================================================
// // THREAD-LOCAL ALLOCATOR
// // ============================================================================

// /**
//  * Thread-local allocator for high-performance memory allocation.
//  *
//  * **Performance Critical**: This is used during compression hot paths.
//  * Every allocation here needs to be as fast as possible.
//  *
//  * **Features**:
//  * - Bump pointer allocation (O(1) allocation time)
//  * - Memory tracking integration
//  * - Thread-safe operation
//  */
// class Allocator implements AdjacencyListBuilder.Allocator<Uint8Array> {

//   private readonly allocator: BumpAllocator.LocalAllocator<Uint8Array>;
//   private readonly memoryTracker: MemoryTracker;

//   constructor(
//     allocator: BumpAllocator.LocalAllocator<Uint8Array>,
//     memoryTracker: MemoryTracker
//   ) {
//     this.allocator = allocator;
//     this.memoryTracker = memoryTracker;
//   }

//   /**
//    * Allocate memory for compressed adjacency data.
//    *
//    * **The Hot Path**: This method is called for every node's adjacency list
//    * during compression. Performance here directly impacts build time.
//    *
//    * **Algorithm**:
//    * 1. Record allocation in memory tracker (for statistics)
//    * 2. Use bump allocator for fast memory allocation
//    * 3. Return address/offset for storing compressed data
//    *
//    * @param allocationSize Number of bytes needed for compressed data
//    * @param into Slice that will receive the allocated memory
//    * @returns Offset/address where data was allocated
//    */
//   async allocate(allocationSize: number, into: ModifiableSlice<Uint8Array>): Promise<number> {
//     // ✅ ANALYTICS: Track heap allocation for compression monitoring
//     this.memoryTracker.recordHeapAllocation(allocationSize);

//     // ✅ FAST ALLOCATION: Bump pointer allocation - just increment pointer!
//     return await this.allocator.insertInto(allocationSize, into);
//   }

//   /**
//    * Clean up allocator resources.
//    * **Note**: Bump allocators typically don't need explicit cleanup
//    */
//   close(): void {
//     // No cleanup needed for bump allocator
//   }
// }
