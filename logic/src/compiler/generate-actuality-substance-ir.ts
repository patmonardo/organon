import fs from 'node:fs/promises';
import path from 'node:path';
import { fileURLToPath } from 'node:url';

import type { DialecticIR, DialecticState } from '@schema/dialectic';
import { DialecticIRSchema } from '@schema/dialectic';
import { reciprocityActionIR } from '@relative/essence/actuality/substance/reciprocity-action-ir';
import { relationCausalityIR } from '@relative/essence/actuality/substance/relation-causality-ir';
import { relationSubstantialityIR } from '@relative/essence/actuality/substance/relation-substantiality-ir';
import { RECIPROCITY_ACTION_TOPIC_MAP } from '@relative/essence/actuality/substance/sources/reciprocity-action-topic-map';
import { RELATION_CAUSALITY_TOPIC_MAP } from '@relative/essence/actuality/substance/sources/relation-causality-topic-map';
import { RELATION_SUBSTANTIALITY_TOPIC_MAP } from '@relative/essence/actuality/substance/sources/relation-substantiality-topic-map';
import type { TopicMapEntry } from '@schema/topic';

type SourceSpec = {
  id: string;
  title: string;
  sourceFile: string;
  topicMap: TopicMapEntry[];
};

type TraceType = 'NEXT' | 'NEGATES' | 'SUBLATES' | 'REFLECTS' | 'MEDIATES';

type TopicMapChunk = {
  id: string;
  title: string;
  sourceId: string;
  sourceFile: string;
  lineRange: { start: number; end: number };
  description: string;
  keyPoints: string[];
  orderInSource: number;
  globalOrder: number;
  sourceText: string;
  tags: string[];
};

type SourceDocument = {
  id: string;
  title: string;
  sourceFile: string;
  totalLines: number;
  chunks: TopicMapChunk[];
};

type Trace = {
  fromChunkId: string;
  toChunkId: string;
  type: TraceType;
  reason: string;
};

type TopicMapIR = {
  id: string;
  mode: 'debug';
  title: string;
  section: string;
  sourceDocuments: SourceDocument[];
  traces: Trace[];
  metadata: {
    totalSources: number;
    totalChunks: number;
    generatedAt: string;
  };
};

type SectionDialecticSpec = {
  fileName: string;
  exportName: string;
  statesExportName: string;
  ir: DialecticIR;
};

const sectionDialecticSpecs: SectionDialecticSpec[] = [
  {
    fileName: 'relation-substantiality-ir.ts',
    exportName: 'relationSubstantialityIR',
    statesExportName: 'relationSubstantialityStates',
    ir: relationSubstantialityIR,
  },
  {
    fileName: 'relation-causality-ir.ts',
    exportName: 'relationCausalityIR',
    statesExportName: 'relationCausalityStates',
    ir: relationCausalityIR,
  },
  {
    fileName: 'reciprocity-action-ir.ts',
    exportName: 'reciprocityActionIR',
    statesExportName: 'reciprocityActionStates',
    ir: reciprocityActionIR,
  },
];

function cypherEscape(value: string): string {
  return value
    .replace(/\\/g, '\\\\')
    .replace(/'/g, "\\'")
    .replace(/\r/g, '\\r')
    .replace(/\n/g, '\\n');
}

function toCypherString(value: string): string {
  return `'${cypherEscape(value)}'`;
}

function toCypherArray(values: string[]): string {
  return `[${values.map(toCypherString).join(', ')}]`;
}

function extractChunkText(
  sourceText: string,
  lineRange: { start: number; end: number },
): string {
  const lines = sourceText.split(/\r?\n/);
  return lines
    .slice(lineRange.start - 1, lineRange.end)
    .join('\n')
    .trim();
}

function inferTraceType(nextChunk: TopicMapChunk): TraceType {
  const body =
    `${nextChunk.title} ${nextChunk.description} ${nextChunk.keyPoints.join(' ')}`.toLowerCase();

  if (body.includes('negation') || body.includes('negative')) return 'NEGATES';
  if (body.includes('sublat')) return 'SUBLATES';
  if (body.includes('mediate')) return 'MEDIATES';
  if (body.includes('reflect') || body.includes('causal')) return 'REFLECTS';
  return 'NEXT';
}

function deriveTags(chunk: TopicMapChunk): string[] {
  const body =
    `${chunk.title} ${chunk.description} ${chunk.keyPoints.join(' ')}`.toLowerCase();
  const tags = new Set<string>();

  if (body.includes('negation') || body.includes('negative')) {
    tags.add('negation');
  }
  if (body.includes('sublat')) {
    tags.add('sublation');
  }
  if (body.includes('reflect')) {
    tags.add('reflection');
  }
  if (body.includes('mediate')) {
    tags.add('mediation');
  }
  if (body.includes('substance') || body.includes('substantial')) {
    tags.add('substance');
  }
  if (
    body.includes('causality') ||
    body.includes('cause') ||
    body.includes('effect')
  ) {
    tags.add('causality');
  }
  if (body.includes('reciprocity')) {
    tags.add('reciprocity');
  }
  if (body.includes('action')) {
    tags.add('action');
  }

  return [...tags];
}

function buildCypher(ir: TopicMapIR): string {
  const statements: string[] = [];

  statements.push('// TopicMap Cypher IR (debug mode)');
  statements.push(
    '// Generated by src/relative/core/compiler/generate-actuality-substance-ir.ts',
  );
  statements.push('');
  statements.push(
    'CREATE CONSTRAINT topicmap_source_id IF NOT EXISTS FOR (s:SourceText) REQUIRE s.id IS UNIQUE;',
  );
  statements.push(
    'CREATE CONSTRAINT topicmap_chunk_id IF NOT EXISTS FOR (c:TopicMapChunk) REQUIRE c.id IS UNIQUE;',
  );
  statements.push(
    'CREATE CONSTRAINT topicmap_kp_id IF NOT EXISTS FOR (k:KeyPoint) REQUIRE k.id IS UNIQUE;',
  );
  statements.push('');

  statements.push(
    `MERGE (ir:TopicMapIR {id: ${toCypherString(ir.id)}}) SET ir.mode = ${toCypherString(ir.mode)}, ir.title = ${toCypherString(ir.title)}, ir.section = ${toCypherString(ir.section)}, ir.generatedAt = ${toCypherString(ir.metadata.generatedAt)}, ir.totalSources = ${ir.metadata.totalSources}, ir.totalChunks = ${ir.metadata.totalChunks};`,
  );
  statements.push('');

  for (const source of ir.sourceDocuments) {
    statements.push(`MERGE (s:SourceText {id: ${toCypherString(source.id)}})`);
    statements.push('SET s.title = ' + toCypherString(source.title));
    statements.push('SET s.sourceFile = ' + toCypherString(source.sourceFile));
    statements.push('SET s.totalLines = ' + String(source.totalLines) + ';');
    statements.push(`MATCH (ir:TopicMapIR {id: ${toCypherString(ir.id)}})`);
    statements.push(`MATCH (s:SourceText {id: ${toCypherString(source.id)}})`);
    statements.push('MERGE (ir)-[:HAS_SOURCE]->(s);');

    for (const chunk of source.chunks) {
      statements.push(
        `MERGE (c:TopicMapChunk {id: ${toCypherString(chunk.id)}})`,
      );
      statements.push('SET c.title = ' + toCypherString(chunk.title));
      statements.push('SET c.sourceId = ' + toCypherString(chunk.sourceId));
      statements.push('SET c.sourceFile = ' + toCypherString(chunk.sourceFile));
      statements.push('SET c.lineStart = ' + String(chunk.lineRange.start));
      statements.push('SET c.lineEnd = ' + String(chunk.lineRange.end));
      statements.push(
        'SET c.description = ' + toCypherString(chunk.description),
      );
      statements.push('SET c.keyPoints = ' + toCypherArray(chunk.keyPoints));
      statements.push('SET c.tags = ' + toCypherArray(chunk.tags));
      statements.push('SET c.orderInSource = ' + String(chunk.orderInSource));
      statements.push('SET c.globalOrder = ' + String(chunk.globalOrder));
      statements.push(
        'SET c.sourceText = ' + toCypherString(chunk.sourceText) + ';',
      );

      statements.push(
        `MATCH (s:SourceText {id: ${toCypherString(source.id)}})`,
      );
      statements.push(
        `MATCH (c:TopicMapChunk {id: ${toCypherString(chunk.id)}})`,
      );
      statements.push('MERGE (s)-[:HAS_CHUNK]->(c);');

      for (let index = 0; index < chunk.keyPoints.length; index += 1) {
        const keyPoint = chunk.keyPoints[index] ?? '';
        const keyPointId = `${chunk.id}:kp:${index + 1}`;

        statements.push(
          `MERGE (kp:KeyPoint {id: ${toCypherString(keyPointId)}})`,
        );
        statements.push('SET kp.chunkId = ' + toCypherString(chunk.id));
        statements.push('SET kp.ordinal = ' + String(index + 1));
        statements.push('SET kp.text = ' + toCypherString(keyPoint) + ';');
        statements.push(
          `MATCH (c:TopicMapChunk {id: ${toCypherString(chunk.id)}})`,
        );
        statements.push(
          `MATCH (kp:KeyPoint {id: ${toCypherString(keyPointId)}})`,
        );
        statements.push('MERGE (c)-[:HAS_KEY_POINT]->(kp);');
      }
    }
  }

  for (const trace of ir.traces) {
    statements.push(
      `MATCH (a:TopicMapChunk {id: ${toCypherString(trace.fromChunkId)}})`,
    );
    statements.push(
      `MATCH (b:TopicMapChunk {id: ${toCypherString(trace.toChunkId)}})`,
    );
    statements.push(`MERGE (a)-[r:${trace.type}]->(b)`);
    statements.push('SET r.reason = ' + toCypherString(trace.reason) + ';');
  }

  return statements.join('\n');
}

function buildQueryPack(ir: TopicMapIR): string {
  return [
    '// Neo4j Query Pack â€” Actuality/Substance IR',
    `// IR: ${ir.id}`,
    `// Generated for section: ${ir.section}`,
    '',
    '// Q1: Graph inventory by labels',
    'MATCH (n)',
    'UNWIND labels(n) AS label',
    'RETURN label, count(*) AS count',
    'ORDER BY count DESC;',
    '',
    '// Q2: Source -> Chunk chain',
    'MATCH (s:SourceText)-[:HAS_CHUNK]->(c:TopicMapChunk)',
    'RETURN s.id AS sourceId, c.id AS chunkId, c.globalOrder AS globalOrder, c.lineStart AS lineStart, c.lineEnd AS lineEnd',
    'ORDER BY c.globalOrder;',
    '',
    '// Q3: Cross-source trace edges',
    'MATCH (a:TopicMapChunk)-[r:NEXT|NEGATES|SUBLATES|REFLECTS|MEDIATES]->(b:TopicMapChunk)',
    'WHERE a.sourceId <> b.sourceId',
    'RETURN a.id AS fromChunk, a.sourceId AS fromSource, type(r) AS rel, b.id AS toChunk, b.sourceId AS toSource, r.reason AS reason',
    'ORDER BY a.globalOrder;',
    '',
    '// Q4: Key points for one chunk (replace chunk id)',
    "MATCH (c:TopicMapChunk {id: 'sub-c-5'})-[:HAS_KEY_POINT]->(k:KeyPoint)",
    'RETURN c.id AS chunkId, k.ordinal AS ordinal, k.text AS keyPoint',
    'ORDER BY k.ordinal;',
  ].join('\n');
}

function toPascalIdentifier(value: string): string {
  const normalized = value
    .replace(/[^a-zA-Z0-9]+/g, ' ')
    .trim()
    .split(/\s+/)
    .filter(Boolean)
    .map((part) => part[0]?.toUpperCase() + part.slice(1))
    .join('');

  if (!normalized) {
    return 'Item';
  }

  if (/^[0-9]/.test(normalized)) {
    return `N${normalized}`;
  }

  return normalized;
}

function renderTopicMapFile(
  constName: string,
  typeName: string,
  sourcePrefix: string,
  ir: TopicMapIR,
): string {
  const sourceLines = ir.sourceDocuments.map((source) => {
    const sourceConst = `${sourcePrefix}Source${toPascalIdentifier(source.id)}`;
    return {
      sourceConst,
      line: `const ${sourceConst} = ${JSON.stringify(source, null, 2)} as const;`,
    };
  });

  const sourceDocList = sourceLines
    .map((source) => source.sourceConst)
    .join(',\n  ');

  return [
    '// Generated by src/relative/core/compiler/generate-actuality-substance-ir.ts',
    '',
    ...sourceLines.map((source) => source.line),
    '',
    `const ${sourcePrefix}Sources = [`,
    `  ${sourceDocList},`,
    '] as const;',
    '',
    `const ${sourcePrefix}Traces = ${JSON.stringify(ir.traces, null, 2)} as const;`,
    '',
    `const ${sourcePrefix}Metadata = ${JSON.stringify(ir.metadata, null, 2)} as const;`,
    '',
    `export const ${constName} = {`,
    `  id: ${JSON.stringify(ir.id)},`,
    `  mode: ${JSON.stringify(ir.mode)},`,
    `  title: ${JSON.stringify(ir.title)},`,
    `  section: ${JSON.stringify(ir.section)},`,
    `  sourceDocuments: ${sourcePrefix}Sources,`,
    `  traces: ${sourcePrefix}Traces,`,
    `  metadata: ${sourcePrefix}Metadata,`,
    '} as const;',
    '',
    `export type ${typeName} = typeof ${constName};`,
    '',
  ].join('\n');
}

function renderSectionDialecticIR(
  exportName: string,
  statesExportName: string,
  ir: DialecticIR,
): string {
  const stateEntries = ir.states.map((state, index) => {
    const baseName = toPascalIdentifier(state.id);
    const constName = `state${baseName || `Index${index + 1}`}`;
    return {
      id: state.id,
      constName,
      content: `const ${constName}: DialecticState = ${JSON.stringify(state, null, 2)};`,
    };
  });

  const stateList = stateEntries
    .map((entry) => entry.constName)
    .join(',\n    ');

  const stateMapEntries = stateEntries
    .map((entry) => `  ${JSON.stringify(entry.id)}: ${entry.constName},`)
    .join('\n');

  return [
    "import type { DialecticIR, DialecticState } from '@schema/dialectic';",
    '',
    '// Generated by src/relative/core/compiler/generate-actuality-substance-ir.ts',
    ...stateEntries.map((entry) => entry.content),
    '',
    `export const ${exportName}: DialecticIR = {`,
    `  id: ${JSON.stringify(ir.id)},`,
    `  title: ${JSON.stringify(ir.title)},`,
    `  section: ${JSON.stringify(ir.section)},`,
    '  states: [',
    `    ${stateList},`,
    '  ],',
    `  metadata: ${JSON.stringify(ir.metadata, null, 2)},`,
    '};',
    '',
    `export const ${statesExportName} = {`,
    stateMapEntries,
    '};',
    '',
  ].join('\n');
}

async function main() {
  const here = path.dirname(fileURLToPath(import.meta.url));
  const packageRoot = path.resolve(here, '..', '..', '..', '..');

  const sourceSpecs: SourceSpec[] = [
    {
      id: 'source-relation-substantiality',
      title: 'A. RELATION OF SUBSTANTIALITY',
      sourceFile:
        'relative/essence/actuality/substance/sources/relation-substantiality.txt',
      topicMap: RELATION_SUBSTANTIALITY_TOPIC_MAP.entries,
    },
    {
      id: 'source-relation-causality',
      title: 'B. RELATION OF CAUSALITY',
      sourceFile:
        'relative/essence/actuality/substance/sources/relation-causality.txt',
      topicMap: RELATION_CAUSALITY_TOPIC_MAP.entries,
    },
    {
      id: 'source-reciprocity-action',
      title: 'C. RECIPROCITY OF ACTION',
      sourceFile:
        'relative/essence/actuality/substance/sources/reciprocity-action.txt',
      topicMap: RECIPROCITY_ACTION_TOPIC_MAP.entries,
    },
  ];

  let globalOrder = 1;
  const traces: Trace[] = [];
  const sourceDocuments: SourceDocument[] = [];

  for (const sourceSpec of sourceSpecs) {
    const sourceAbsPath = path.join(packageRoot, 'src', sourceSpec.sourceFile);
    const fullSource = await fs.readFile(sourceAbsPath, 'utf8');
    const totalLines = fullSource.split(/\r?\n/).length;

    const chunks: TopicMapChunk[] = sourceSpec.topicMap.map((entry, index) => {
      const sourceText = extractChunkText(fullSource, entry.lineRange);
      const chunk: TopicMapChunk = {
        id: entry.id,
        title: entry.title,
        sourceId: sourceSpec.id,
        sourceFile: sourceSpec.sourceFile,
        lineRange: {
          start: entry.lineRange.start,
          end: entry.lineRange.end,
        },
        description: entry.description,
        keyPoints: entry.keyPoints,
        orderInSource: index + 1,
        globalOrder,
        sourceText,
        tags: [],
      };

      chunk.tags = deriveTags(chunk);
      globalOrder += 1;
      return chunk;
    });

    for (let index = 0; index < chunks.length - 1; index += 1) {
      const current = chunks[index];
      const next = chunks[index + 1];
      if (!current || !next) continue;

      traces.push({
        fromChunkId: current.id,
        toChunkId: next.id,
        type: 'NEXT',
        reason: 'Sequential order in source text.',
      });

      const inferredType = inferTraceType(next);
      if (inferredType !== 'NEXT') {
        traces.push({
          fromChunkId: current.id,
          toChunkId: next.id,
          type: inferredType,
          reason: `Dialectical transition inferred from ${next.id} semantics.`,
        });
      }
    }

    sourceDocuments.push({
      id: sourceSpec.id,
      title: sourceSpec.title,
      sourceFile: sourceSpec.sourceFile,
      totalLines,
      chunks,
    });
  }

  const boundaryReasons = [
    'Substantiality passes into explicit causality relation.',
    'Causality passes into reciprocity of action.',
  ];

  for (let index = 0; index < sourceDocuments.length - 1; index += 1) {
    const from = sourceDocuments[index]?.chunks.at(-1);
    const to = sourceDocuments[index + 1]?.chunks[0];
    if (!from || !to) continue;

    traces.push({
      fromChunkId: from.id,
      toChunkId: to.id,
      type: 'SUBLATES',
      reason: boundaryReasons[index] ?? 'Transition between source sections.',
    });
  }

  const ir: TopicMapIR = {
    id: 'actuality-substance-topicmap-ir',
    mode: 'debug',
    title: 'Actuality-Substance TopicMap IR',
    section: 'Doctrine of Essence / Actuality / Substance',
    sourceDocuments,
    traces,
    metadata: {
      totalSources: sourceDocuments.length,
      totalChunks: sourceDocuments.reduce(
        (sum, source) => sum + source.chunks.length,
        0,
      ),
      generatedAt: new Date().toISOString(),
    },
  };

  const outputDir = path.join(
    packageRoot,
    'src',
    'relative',
    'essence',
    'actuality',
    'substance',
    'sources',
    'generated',
  );

  const topLevelIrPath = path.join(
    packageRoot,
    'src',
    'relative',
    'essence',
    'actuality',
    'substance',
    'topicmap-ir.ts',
  );

  await fs.mkdir(outputDir, { recursive: true });

  const cypherPath = path.join(outputDir, 'topicmap-ir.cypher');
  const queryPath = path.join(outputDir, 'topicmap-query-pack.cypher');
  const debugTsPath = path.join(outputDir, 'topicmap-ir.debug.ts');

  const debugTs = renderTopicMapFile(
    'topicMapDebug',
    'TopicMapDebug',
    'topicMapDebug',
    ir,
  );

  const topLevelTs = renderTopicMapFile(
    'topicmapActualitySubstanceTopicMapIR',
    'ActualitySubstanceTopicMapIR',
    'topicmapActualitySubstanceTopicMap',
    ir,
  );

  const sectionDialecticOutputs = sectionDialecticSpecs.map((spec) => {
    const parsed = DialecticIRSchema.safeParse(spec.ir);
    if (!parsed.success) {
      const issues = parsed.error.issues
        .map((issue) => `${issue.path.join('.')}: ${issue.message}`)
        .join('\n');
      throw new Error(
        `Actuality-substance section DialecticIR validation failed (${spec.fileName}):\n${issues}`,
      );
    }

    const content = renderSectionDialecticIR(
      spec.exportName,
      spec.statesExportName,
      parsed.data,
    );

    const filePath = path.join(
      packageRoot,
      'src',
      'relative',
      'essence',
      'actuality',
      'substance',
      spec.fileName,
    );

    return { filePath, content };
  });

  await fs.writeFile(cypherPath, buildCypher(ir), 'utf8');
  await fs.writeFile(queryPath, buildQueryPack(ir), 'utf8');
  await fs.writeFile(debugTsPath, debugTs, 'utf8');
  await fs.writeFile(topLevelIrPath, topLevelTs, 'utf8');
  await Promise.all(
    sectionDialecticOutputs.map((output) =>
      fs.writeFile(output.filePath, output.content, 'utf8'),
    ),
  );

  console.log(
    `Generated ${path.relative(packageRoot, cypherPath)}, ${path.relative(packageRoot, queryPath)}, ${path.relative(packageRoot, debugTsPath)}, ${path.relative(packageRoot, topLevelIrPath)}, and ${sectionDialecticOutputs.length} section DialecticIR files.`,
  );
}

await main();
