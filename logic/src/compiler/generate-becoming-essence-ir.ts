import fs from 'node:fs/promises';
import path from 'node:path';
import { fileURLToPath } from 'node:url';

import type { DialecticIR, DialecticState } from '@schema/dialectic';
import { DialecticIRSchema } from '@schema/dialectic';
import { absoluteIndifferenceIR } from '@relative/being/measure/becoming-essence/absolute-indifference-ir';
import { indifferenceInverseRatioIR } from '@relative/being/measure/becoming-essence/indifference-inverse-ratio-ir';
import { transitionEssenceIR } from '@relative/being/measure/becoming-essence/transition-essence-ir';
import { ABSOLUTE_INDIFFERENCE_TOPIC_MAP } from '@relative/being/measure/becoming-essence/sources/absolute-indifference-topic-map';
import { INDIFFERENCE_INVERSE_RATIO_TOPIC_MAP } from '@relative/being/measure/becoming-essence/sources/indifference-inverse-ratio-topic-map';
import { TRANSITION_ESSENCE_TOPIC_MAP } from '@relative/being/measure/becoming-essence/sources/transition-essence-topic-map';
import type { TopicMapEntry } from '@schema/topic';

type SourceSpec = {
  id: string;
  title: string;
  sourceFile: string;
  topicMap: TopicMapEntry[];
};

type TraceType = 'NEXT' | 'NEGATES' | 'SUBLATES' | 'REFLECTS' | 'MEDIATES';

type IntegratedChunk = {
  id: string;
  title: string;
  sourceId: string;
  sourceFile: string;
  lineRange: { start: number; end: number };
  description: string;
  keyPoints: string[];
  orderInSource: number;
  globalOrder: number;
  sourceText: string;
  tags: string[];
};

type IntegratedSourceDocument = {
  id: string;
  title: string;
  sourceFile: string;
  totalLines: number;
  chunks: IntegratedChunk[];
};

type IntegratedTrace = {
  fromChunkId: string;
  toChunkId: string;
  type: TraceType;
  reason: string;
};

type IntegratedIR = {
  id: string;
  mode: 'debug';
  title: string;
  section: string;
  sourceDocuments: IntegratedSourceDocument[];
  traces: IntegratedTrace[];
  metadata: {
    totalSources: number;
    totalChunks: number;
    generatedAt: string;
  };
};

type SectionDialecticSpec = {
  fileName: string;
  exportName: string;
  statesExportName: string;
  ir: DialecticIR;
};

const sectionDialecticSpecs: SectionDialecticSpec[] = [
  {
    fileName: 'absolute-indifference-ir.ts',
    exportName: 'absoluteIndifferenceIR',
    statesExportName: 'absoluteIndifferenceStates',
    ir: absoluteIndifferenceIR,
  },
  {
    fileName: 'indifference-inverse-ratio-ir.ts',
    exportName: 'indifferenceInverseRatioIR',
    statesExportName: 'indifferenceInverseRatioStates',
    ir: indifferenceInverseRatioIR,
  },
  {
    fileName: 'transition-essence-ir.ts',
    exportName: 'transitionEssenceIR',
    statesExportName: 'transitionEssenceStates',
    ir: transitionEssenceIR,
  },
];

function cypherEscape(value: string): string {
  return value
    .replace(/\\/g, '\\\\')
    .replace(/'/g, "\\'")
    .replace(/\r/g, '\\r')
    .replace(/\n/g, '\\n');
}

function toCypherString(value: string): string {
  return `'${cypherEscape(value)}'`;
}

function toCypherArray(values: string[]): string {
  return `[${values.map(toCypherString).join(', ')}]`;
}

function extractChunkText(
  sourceText: string,
  lineRange: { start: number; end: number },
): string {
  const lines = sourceText.split(/\r?\n/);
  return lines
    .slice(lineRange.start - 1, lineRange.end)
    .join('\n')
    .trim();
}

function inferTraceType(nextChunk: IntegratedChunk): TraceType {
  const body =
    `${nextChunk.title} ${nextChunk.description} ${nextChunk.keyPoints.join(' ')}`.toLowerCase();

  if (body.includes('negation') || body.includes('negative')) return 'NEGATES';
  if (body.includes('sublat')) return 'SUBLATES';
  if (body.includes('mediate')) return 'MEDIATES';
  if (body.includes('reflect') || body.includes('essence')) return 'REFLECTS';
  return 'NEXT';
}

function deriveTags(chunk: IntegratedChunk): string[] {
  const body =
    `${chunk.title} ${chunk.description} ${chunk.keyPoints.join(' ')}`.toLowerCase();
  const tags = new Set<string>();

  if (body.includes('negation') || body.includes('negative')) {
    tags.add('negation');
  }
  if (body.includes('sublat')) {
    tags.add('sublation');
  }
  if (body.includes('reflect')) {
    tags.add('reflection');
  }
  if (body.includes('mediate')) {
    tags.add('mediation');
  }
  if (body.includes('measure')) {
    tags.add('measure');
  }
  if (body.includes('indifference')) {
    tags.add('indifference');
  }
  if (body.includes('inverse ratio') || body.includes('inverse')) {
    tags.add('inverse-ratio');
  }
  if (body.includes('contradiction')) {
    tags.add('contradiction');
  }
  if (body.includes('essence')) {
    tags.add('essence');
  }

  return [...tags];
}

function buildCypher(ir: IntegratedIR): string {
  const statements: string[] = [];

  statements.push('// Integrated TopicMap Cypher IR (debug mode)');
  statements.push(
    '// Generated by src/relative/core/compiler/generate-becoming-essence-ir.ts',
  );
  statements.push('');
  statements.push(
    'CREATE CONSTRAINT integrated_source_id IF NOT EXISTS FOR (s:SourceText) REQUIRE s.id IS UNIQUE;',
  );
  statements.push(
    'CREATE CONSTRAINT integrated_chunk_id IF NOT EXISTS FOR (c:IntegratedChunk) REQUIRE c.id IS UNIQUE;',
  );
  statements.push(
    'CREATE CONSTRAINT integrated_kp_id IF NOT EXISTS FOR (k:KeyPoint) REQUIRE k.id IS UNIQUE;',
  );
  statements.push('');

  statements.push(
    `MERGE (ir:IntegratedIR {id: ${toCypherString(ir.id)}}) SET ir.mode = ${toCypherString(ir.mode)}, ir.title = ${toCypherString(ir.title)}, ir.section = ${toCypherString(ir.section)}, ir.generatedAt = ${toCypherString(ir.metadata.generatedAt)}, ir.totalSources = ${ir.metadata.totalSources}, ir.totalChunks = ${ir.metadata.totalChunks};`,
  );
  statements.push('');

  for (const source of ir.sourceDocuments) {
    statements.push(`MERGE (s:SourceText {id: ${toCypherString(source.id)}})`);
    statements.push('SET s.title = ' + toCypherString(source.title));
    statements.push('SET s.sourceFile = ' + toCypherString(source.sourceFile));
    statements.push('SET s.totalLines = ' + String(source.totalLines) + ';');
    statements.push(`MATCH (ir:IntegratedIR {id: ${toCypherString(ir.id)}})`);
    statements.push(`MATCH (s:SourceText {id: ${toCypherString(source.id)}})`);
    statements.push('MERGE (ir)-[:HAS_SOURCE]->(s);');

    for (const chunk of source.chunks) {
      statements.push(
        `MERGE (c:IntegratedChunk {id: ${toCypherString(chunk.id)}})`,
      );
      statements.push('SET c.title = ' + toCypherString(chunk.title));
      statements.push('SET c.sourceId = ' + toCypherString(chunk.sourceId));
      statements.push('SET c.sourceFile = ' + toCypherString(chunk.sourceFile));
      statements.push('SET c.lineStart = ' + String(chunk.lineRange.start));
      statements.push('SET c.lineEnd = ' + String(chunk.lineRange.end));
      statements.push(
        'SET c.description = ' + toCypherString(chunk.description),
      );
      statements.push('SET c.keyPoints = ' + toCypherArray(chunk.keyPoints));
      statements.push('SET c.tags = ' + toCypherArray(chunk.tags));
      statements.push('SET c.orderInSource = ' + String(chunk.orderInSource));
      statements.push('SET c.globalOrder = ' + String(chunk.globalOrder));
      statements.push(
        'SET c.sourceText = ' + toCypherString(chunk.sourceText) + ';',
      );

      statements.push(
        `MATCH (s:SourceText {id: ${toCypherString(source.id)}})`,
      );
      statements.push(
        `MATCH (c:IntegratedChunk {id: ${toCypherString(chunk.id)}})`,
      );
      statements.push('MERGE (s)-[:HAS_CHUNK]->(c);');

      for (let index = 0; index < chunk.keyPoints.length; index += 1) {
        const keyPoint = chunk.keyPoints[index] ?? '';
        const keyPointId = `${chunk.id}:kp:${index + 1}`;

        statements.push(
          `MERGE (kp:KeyPoint {id: ${toCypherString(keyPointId)}})`,
        );
        statements.push('SET kp.chunkId = ' + toCypherString(chunk.id));
        statements.push('SET kp.ordinal = ' + String(index + 1));
        statements.push('SET kp.text = ' + toCypherString(keyPoint) + ';');
        statements.push(
          `MATCH (c:IntegratedChunk {id: ${toCypherString(chunk.id)}})`,
        );
        statements.push(
          `MATCH (kp:KeyPoint {id: ${toCypherString(keyPointId)}})`,
        );
        statements.push('MERGE (c)-[:HAS_KEY_POINT]->(kp);');
      }
    }
  }

  for (const trace of ir.traces) {
    statements.push(
      `MATCH (a:IntegratedChunk {id: ${toCypherString(trace.fromChunkId)}})`,
    );
    statements.push(
      `MATCH (b:IntegratedChunk {id: ${toCypherString(trace.toChunkId)}})`,
    );
    statements.push(`MERGE (a)-[r:${trace.type}]->(b)`);
    statements.push('SET r.reason = ' + toCypherString(trace.reason) + ';');
  }

  return statements.join('\n');
}

function buildQueryPack(ir: IntegratedIR): string {
  return [
    '// Neo4j Query Pack â€” Integrated Becoming Essence IR',
    `// IR: ${ir.id}`,
    `// Generated for section: ${ir.section}`,
    '',
    '// Q1: Graph inventory by labels',
    'MATCH (n)',
    'UNWIND labels(n) AS label',
    'RETURN label, count(*) AS count',
    'ORDER BY count DESC;',
    '',
    '// Q2: Source -> Chunk chain',
    'MATCH (s:SourceText)-[:HAS_CHUNK]->(c:IntegratedChunk)',
    'RETURN s.id AS sourceId, c.id AS chunkId, c.globalOrder AS globalOrder, c.lineStart AS lineStart, c.lineEnd AS lineEnd',
    'ORDER BY c.globalOrder;',
    '',
    '// Q3: Cross-source trace edges',
    'MATCH (a:IntegratedChunk)-[r:NEXT|NEGATES|SUBLATES|REFLECTS|MEDIATES]->(b:IntegratedChunk)',
    'WHERE a.sourceId <> b.sourceId',
    'RETURN a.id AS fromChunk, a.sourceId AS fromSource, type(r) AS rel, b.id AS toChunk, b.sourceId AS toSource, r.reason AS reason',
    'ORDER BY a.globalOrder;',
    '',
    '// Q4: Key points for one chunk (replace chunk id)',
    "MATCH (c:IntegratedChunk {id: 'be-c-4-being-determined-as-essence'})-[:HAS_KEY_POINT]->(k:KeyPoint)",
    'RETURN c.id AS chunkId, k.ordinal AS ordinal, k.text AS keyPoint',
    'ORDER BY k.ordinal;',
  ].join('\n');
}

function toPascalIdentifier(value: string): string {
  const normalized = value
    .replace(/[^a-zA-Z0-9]+/g, ' ')
    .trim()
    .split(/\s+/)
    .filter(Boolean)
    .map((part) => part[0]?.toUpperCase() + part.slice(1))
    .join('');

  if (!normalized) {
    return 'Item';
  }

  if (/^[0-9]/.test(normalized)) {
    return `N${normalized}`;
  }

  return normalized;
}

function renderIntegratedTopicMapFile(
  constName: string,
  typeName: string,
  sourcePrefix: string,
  ir: IntegratedIR,
): string {
  const sourceLines = ir.sourceDocuments.map((source) => {
    const sourceConst = `${sourcePrefix}Source${toPascalIdentifier(source.id)}`;
    return {
      sourceConst,
      line: `const ${sourceConst} = ${JSON.stringify(source, null, 2)} as const;`,
    };
  });

  const sourceDocList = sourceLines
    .map((source) => source.sourceConst)
    .join(',\n  ');

  return [
    '// Generated by src/relative/core/compiler/generate-becoming-essence-ir.ts',
    '',
    ...sourceLines.map((source) => source.line),
    '',
    `const ${sourcePrefix}Sources = [`,
    `  ${sourceDocList},`,
    '] as const;',
    '',
    `const ${sourcePrefix}Traces = ${JSON.stringify(ir.traces, null, 2)} as const;`,
    '',
    `const ${sourcePrefix}Metadata = ${JSON.stringify(ir.metadata, null, 2)} as const;`,
    '',
    `export const ${constName} = {`,
    `  id: ${JSON.stringify(ir.id)},`,
    `  mode: ${JSON.stringify(ir.mode)},`,
    `  title: ${JSON.stringify(ir.title)},`,
    `  section: ${JSON.stringify(ir.section)},`,
    `  sourceDocuments: ${sourcePrefix}Sources,`,
    `  traces: ${sourcePrefix}Traces,`,
    `  metadata: ${sourcePrefix}Metadata,`,
    '} as const;',
    '',
    `export type ${typeName} = typeof ${constName};`,
    '',
  ].join('\n');
}

function renderSectionDialecticIR(
  exportName: string,
  statesExportName: string,
  ir: DialecticIR,
): string {
  const stateEntries = ir.states.map((state, index) => {
    const baseName = toPascalIdentifier(state.id);
    const constName = `state${baseName || `Index${index + 1}`}`;
    return {
      id: state.id,
      constName,
      content: `const ${constName}: DialecticState = ${JSON.stringify(state, null, 2)};`,
    };
  });

  const stateList = stateEntries
    .map((entry) => entry.constName)
    .join(',\n    ');

  const stateMapEntries = stateEntries
    .map((entry) => `  ${JSON.stringify(entry.id)}: ${entry.constName},`)
    .join('\n');

  return [
    "import type { DialecticIR, DialecticState } from '@schema/dialectic';",
    '',
    '// Generated by src/relative/core/compiler/generate-becoming-essence-ir.ts',
    ...stateEntries.map((entry) => entry.content),
    '',
    `export const ${exportName}: DialecticIR = {`,
    `  id: ${JSON.stringify(ir.id)},`,
    `  title: ${JSON.stringify(ir.title)},`,
    `  section: ${JSON.stringify(ir.section)},`,
    '  states: [',
    `    ${stateList},`,
    '  ],',
    `  metadata: ${JSON.stringify(ir.metadata, null, 2)},`,
    '};',
    '',
    `export const ${statesExportName} = {`,
    stateMapEntries,
    '};',
    '',
  ].join('\n');
}

async function main() {
  const here = path.dirname(fileURLToPath(import.meta.url));
  const packageRoot = path.resolve(here, '..', '..', '..', '..');

  const sourceSpecs: SourceSpec[] = [
    {
      id: 'source-absolute-indifference',
      title: 'A. ABSOLUTE INDIFFERENCE',
      sourceFile:
        'relative/being/measure/becoming-essence/sources/absolute-indifference.txt',
      topicMap: ABSOLUTE_INDIFFERENCE_TOPIC_MAP.entries,
    },
    {
      id: 'source-indifference-inverse-ratio',
      title: 'B. INDIFFERENCE AS INVERSE RATIO OF ITS FACTORS',
      sourceFile:
        'relative/being/measure/becoming-essence/sources/indifference-inverse-ratio.txt',
      topicMap: INDIFFERENCE_INVERSE_RATIO_TOPIC_MAP.entries,
    },
    {
      id: 'source-transition-essence',
      title: 'C. TRANSITION INTO ESSENCE',
      sourceFile:
        'relative/being/measure/becoming-essence/sources/transition-essence.txt',
      topicMap: TRANSITION_ESSENCE_TOPIC_MAP.entries,
    },
  ];

  let globalOrder = 1;
  const traces: IntegratedTrace[] = [];
  const sourceDocuments: IntegratedSourceDocument[] = [];

  for (const sourceSpec of sourceSpecs) {
    const sourceAbsPath = path.join(packageRoot, 'src', sourceSpec.sourceFile);
    const fullSource = await fs.readFile(sourceAbsPath, 'utf8');
    const totalLines = fullSource.split(/\r?\n/).length;

    const chunks: IntegratedChunk[] = sourceSpec.topicMap.map(
      (entry, index) => {
        const sourceText = extractChunkText(fullSource, entry.lineRange);
        const chunk: IntegratedChunk = {
          id: entry.id,
          title: entry.title,
          sourceId: sourceSpec.id,
          sourceFile: sourceSpec.sourceFile,
          lineRange: entry.lineRange,
          description: entry.description,
          keyPoints: entry.keyPoints,
          orderInSource: index + 1,
          globalOrder,
          sourceText,
          tags: [],
        };

        chunk.tags = deriveTags(chunk);
        globalOrder += 1;
        return chunk;
      },
    );

    for (let index = 0; index < chunks.length - 1; index += 1) {
      const current = chunks[index];
      const next = chunks[index + 1];
      if (!current || !next) continue;

      traces.push({
        fromChunkId: current.id,
        toChunkId: next.id,
        type: 'NEXT',
        reason: 'Sequential order in source text.',
      });

      const inferredType = inferTraceType(next);
      if (inferredType !== 'NEXT') {
        traces.push({
          fromChunkId: current.id,
          toChunkId: next.id,
          type: inferredType,
          reason: `Dialectical transition inferred from ${next.id} semantics.`,
        });
      }
    }

    sourceDocuments.push({
      id: sourceSpec.id,
      title: sourceSpec.title,
      sourceFile: sourceSpec.sourceFile,
      totalLines,
      chunks,
    });
  }

  traces.push({
    fromChunkId: 'be-a-3-vanishing-determinateness',
    toChunkId: 'be-b-intro-posited-in-indifference',
    type: 'SUBLATES',
    reason: 'Absolute indifference passes into inverse-ratio self-positing.',
  });

  traces.push({
    fromChunkId: 'be-b-3-contradiction-essence',
    toChunkId: 'be-c-1-absolute-indifference-final-determination',
    type: 'SUBLATES',
    reason:
      'Contradiction in inverse ratio develops into explicit transition to essence.',
  });

  const ir: IntegratedIR = {
    id: 'integrated-becoming-essence-topicmap-ir',
    mode: 'debug',
    title: 'Integrated Becoming Essence TopicMap IR',
    section: 'Doctrine of Being / Measure / Becoming of Essence',
    sourceDocuments,
    traces,
    metadata: {
      totalSources: sourceDocuments.length,
      totalChunks: sourceDocuments.reduce(
        (sum, source) => sum + source.chunks.length,
        0,
      ),
      generatedAt: new Date().toISOString(),
    },
  };

  const outputDir = path.join(
    packageRoot,
    'src',
    'relative',
    'being',
    'measure',
    'becoming-essence',
    'sources',
    'generated',
  );

  const topLevelIrPath = path.join(
    packageRoot,
    'src',
    'relative',
    'being',
    'measure',
    'becoming-essence',
    'integrated-topicmap-ir.ts',
  );

  await fs.mkdir(outputDir, { recursive: true });

  const cypherPath = path.join(outputDir, 'integrated-topicmap-ir.cypher');
  const queryPath = path.join(
    outputDir,
    'integrated-topicmap-query-pack.cypher',
  );
  const debugTsPath = path.join(outputDir, 'integrated-topicmap-ir.debug.ts');

  const debugTs = renderIntegratedTopicMapFile(
    'integratedTopicMapDebug',
    'IntegratedTopicMapDebug',
    'integratedTopicMapDebug',
    ir,
  );

  const topLevelTs = renderIntegratedTopicMapFile(
    'integratedBecomingEssenceTopicMapIR',
    'IntegratedBecomingEssenceTopicMapIR',
    'integratedBecomingEssenceTopicMap',
    ir,
  );

  const sectionDialecticOutputs = sectionDialecticSpecs.map((spec) => {
    const parsed = DialecticIRSchema.safeParse(spec.ir);
    if (!parsed.success) {
      const issues = parsed.error.issues
        .map((issue) => `${issue.path.join('.')}: ${issue.message}`)
        .join('\n');
      throw new Error(
        `Becoming-essence section DialecticIR validation failed (${spec.fileName}):\n${issues}`,
      );
    }

    const content = renderSectionDialecticIR(
      spec.exportName,
      spec.statesExportName,
      parsed.data,
    );

    const filePath = path.join(
      packageRoot,
      'src',
      'relative',
      'being',
      'measure',
      'becoming-essence',
      spec.fileName,
    );

    return { filePath, content };
  });

  await fs.writeFile(cypherPath, buildCypher(ir), 'utf8');
  await fs.writeFile(queryPath, buildQueryPack(ir), 'utf8');
  await fs.writeFile(debugTsPath, debugTs, 'utf8');
  await fs.writeFile(topLevelIrPath, topLevelTs, 'utf8');
  await Promise.all(
    sectionDialecticOutputs.map((output) =>
      fs.writeFile(output.filePath, output.content, 'utf8'),
    ),
  );

  console.log(
    `Generated ${path.relative(packageRoot, cypherPath)}, ${path.relative(packageRoot, queryPath)}, ${path.relative(packageRoot, debugTsPath)}, ${path.relative(packageRoot, topLevelIrPath)}, and ${sectionDialecticOutputs.length} section DialecticIR files.`,
  );
}

await main();
