import fs from 'node:fs/promises';
import path from 'node:path';
import { fileURLToPath } from 'node:url';

import type { DialecticIR } from '@schema/dialectic';
import { DialecticIRSchema } from '@schema/dialectic';
import { beingIR } from '@relative/being/quality/being/being-ir';
import { becomingIR } from '@relative/being/quality/being/becoming-ir';
import { beingTopicMap } from '@relative/being/quality/being/sources/being-topic-map';
import {
  becomingConceptTopics,
  becomingTopicMap,
} from '@relative/being/quality/being/sources/becoming-topic-map';
import { nothingIR } from '@relative/being/quality/being/nothing-ir';
import { nothingTopicMap } from '@relative/being/quality/being/sources/nothing-topic-map';
import type { TopicMapEntry } from '@schema/topic';

type SourceSpec = {
  id: string;
  title: string;
  sourceFile: string;
  topicMap: TopicMapEntry[];
};

type TraceType = 'NEXT' | 'NEGATES' | 'SUBLATES' | 'REFLECTS' | 'MEDIATES';

type IntegratedChunk = {
  id: string;
  title: string;
  sourceId: string;
  sourceFile: string;
  lineRange: { start: number; end: number };
  description: string;
  keyPoints: string[];
  orderInSource: number;
  globalOrder: number;
  sourceText: string;
  tags: string[];
};

type IntegratedSourceDocument = {
  id: string;
  title: string;
  sourceFile: string;
  totalLines: number;
  chunks: IntegratedChunk[];
};

type IntegratedTrace = {
  fromChunkId: string;
  toChunkId: string;
  type: TraceType;
  reason: string;
};

type IntegratedTopic = {
  id: string;
  name: string;
  level: number;
  path: string;
  ordinal: number;
  parentId: string | null;
};

type ChunkTopicLink = {
  chunkId: string;
  topicId: string;
  reason: string;
};

type IntegratedIR = {
  id: string;
  mode: 'debug';
  title: string;
  section: string;
  sourceDocuments: IntegratedSourceDocument[];
  traces: IntegratedTrace[];
  topics: IntegratedTopic[];
  chunkTopicLinks: ChunkTopicLink[];
  metadata: {
    totalSources: number;
    totalChunks: number;
    totalTopics: number;
    totalChunkTopicLinks: number;
    generatedAt: string;
  };
};

type ConceptTopicSeed = {
  id: string;
  name: string;
  parentId: string | null;
  evidenceChunks: string[];
};

type SectionDialecticSpec = {
  fileName: string;
  exportName: string;
  statesExportName: string;
  ir: DialecticIR;
};

const sectionDialecticSpecs: SectionDialecticSpec[] = [
  {
    fileName: 'being-ir.ts',
    exportName: 'beingIR',
    statesExportName: 'beingStates',
    ir: beingIR,
  },
  {
    fileName: 'nothing-ir.ts',
    exportName: 'nothingIR',
    statesExportName: 'nothingStates',
    ir: nothingIR,
  },
  {
    fileName: 'becoming-ir.ts',
    exportName: 'becomingIR',
    statesExportName: 'becomingStates',
    ir: becomingIR,
  },
];

function cypherEscape(value: string): string {
  return value
    .replace(/\\/g, '\\\\')
    .replace(/'/g, "\\'")
    .replace(/\r/g, '\\r')
    .replace(/\n/g, '\\n');
}

function toCypherString(value: string): string {
  return `'${cypherEscape(value)}'`;
}

function toCypherArray(values: string[]): string {
  return `[${values.map(toCypherString).join(', ')}]`;
}

function extractChunkText(
  sourceText: string,
  lineRange: { start: number; end: number },
): string {
  const lines = sourceText.split(/\r?\n/);
  return lines
    .slice(lineRange.start - 1, lineRange.end)
    .join('\n')
    .trim();
}

function deriveTags(chunk: IntegratedChunk): string[] {
  const body =
    `${chunk.title} ${chunk.description} ${chunk.keyPoints.join(' ')}`.toLowerCase();
  const tags = new Set<string>();

  if (body.includes('negation') || body.includes('negative')) {
    tags.add('negation');
  }
  if (body.includes('sublat')) {
    tags.add('sublation');
  }
  if (body.includes('reflect')) {
    tags.add('reflection');
  }
  if (body.includes('mediate')) {
    tags.add('mediation');
  }
  if (body.includes('nothing')) {
    tags.add('nothing');
  }
  if (body.includes('being')) {
    tags.add('being');
  }
  if (body.includes('becoming')) {
    tags.add('becoming');
  }
  if (body.includes('existence')) {
    tags.add('existence');
  }

  return [...tags];
}

function buildCypher(ir: IntegratedIR): string {
  const statements: string[] = [];

  statements.push('// Integrated TopicMap Cypher IR (debug mode)');
  statements.push(
    '// Generated by src/relative/core/compiler/generate-being-ir.ts',
  );
  statements.push('');
  statements.push(
    'CREATE CONSTRAINT integrated_source_id IF NOT EXISTS FOR (s:SourceText) REQUIRE s.id IS UNIQUE;',
  );
  statements.push(
    'CREATE CONSTRAINT integrated_chunk_id IF NOT EXISTS FOR (c:IntegratedChunk) REQUIRE c.id IS UNIQUE;',
  );
  statements.push(
    'CREATE CONSTRAINT integrated_kp_id IF NOT EXISTS FOR (k:KeyPoint) REQUIRE k.id IS UNIQUE;',
  );
  statements.push(
    'CREATE CONSTRAINT integrated_topic_id IF NOT EXISTS FOR (t:Topic) REQUIRE t.id IS UNIQUE;',
  );
  statements.push('');

  statements.push(
    `MERGE (ir:IntegratedIR {id: ${toCypherString(ir.id)}}) SET ir.mode = ${toCypherString(ir.mode)}, ir.title = ${toCypherString(ir.title)}, ir.section = ${toCypherString(ir.section)}, ir.generatedAt = ${toCypherString(ir.metadata.generatedAt)}, ir.totalSources = ${ir.metadata.totalSources}, ir.totalChunks = ${ir.metadata.totalChunks}, ir.totalTopics = ${ir.metadata.totalTopics}, ir.totalChunkTopicLinks = ${ir.metadata.totalChunkTopicLinks};`,
  );
  statements.push('');

  for (const topic of ir.topics) {
    statements.push(`MERGE (t:Topic {id: ${toCypherString(topic.id)}})`);
    statements.push('SET t.name = ' + toCypherString(topic.name));
    statements.push('SET t.level = ' + String(topic.level));
    statements.push('SET t.path = ' + toCypherString(topic.path));
    statements.push('SET t.ordinal = ' + String(topic.ordinal) + ';');
    statements.push(`MATCH (ir:IntegratedIR {id: ${toCypherString(ir.id)}})`);
    statements.push(`MATCH (t:Topic {id: ${toCypherString(topic.id)}})`);
    statements.push('MERGE (ir)-[:HAS_TOPIC]->(t);');

    if (topic.parentId) {
      statements.push(
        `MATCH (parent:Topic {id: ${toCypherString(topic.parentId)}})`,
      );
      statements.push(`MATCH (child:Topic {id: ${toCypherString(topic.id)}})`);
      statements.push('MERGE (parent)-[:PARENT_OF]->(child);');
    }
  }

  statements.push('');

  for (const source of ir.sourceDocuments) {
    statements.push(`MERGE (s:SourceText {id: ${toCypherString(source.id)}})`);
    statements.push('SET s.title = ' + toCypherString(source.title));
    statements.push('SET s.sourceFile = ' + toCypherString(source.sourceFile));
    statements.push('SET s.totalLines = ' + String(source.totalLines) + ';');
    statements.push(`MATCH (ir:IntegratedIR {id: ${toCypherString(ir.id)}})`);
    statements.push(`MATCH (s:SourceText {id: ${toCypherString(source.id)}})`);
    statements.push('MERGE (ir)-[:HAS_SOURCE]->(s);');

    for (const chunk of source.chunks) {
      statements.push(
        `MERGE (c:IntegratedChunk {id: ${toCypherString(chunk.id)}})`,
      );
      statements.push('SET c.title = ' + toCypherString(chunk.title));
      statements.push('SET c.sourceId = ' + toCypherString(chunk.sourceId));
      statements.push('SET c.sourceFile = ' + toCypherString(chunk.sourceFile));
      statements.push('SET c.lineStart = ' + String(chunk.lineRange.start));
      statements.push('SET c.lineEnd = ' + String(chunk.lineRange.end));
      statements.push(
        'SET c.description = ' + toCypherString(chunk.description),
      );
      statements.push('SET c.keyPoints = ' + toCypherArray(chunk.keyPoints));
      statements.push('SET c.tags = ' + toCypherArray(chunk.tags));
      statements.push('SET c.orderInSource = ' + String(chunk.orderInSource));
      statements.push('SET c.globalOrder = ' + String(chunk.globalOrder));
      statements.push(
        'SET c.sourceText = ' + toCypherString(chunk.sourceText) + ';',
      );

      statements.push(
        `MATCH (s:SourceText {id: ${toCypherString(source.id)}})`,
      );
      statements.push(
        `MATCH (c:IntegratedChunk {id: ${toCypherString(chunk.id)}})`,
      );
      statements.push('MERGE (s)-[:HAS_CHUNK]->(c);');

      for (let index = 0; index < chunk.keyPoints.length; index += 1) {
        const keyPoint = chunk.keyPoints[index] ?? '';
        const keyPointId = `${chunk.id}:kp:${index + 1}`;

        statements.push(
          `MERGE (kp:KeyPoint {id: ${toCypherString(keyPointId)}})`,
        );
        statements.push('SET kp.chunkId = ' + toCypherString(chunk.id));
        statements.push('SET kp.ordinal = ' + String(index + 1));
        statements.push('SET kp.text = ' + toCypherString(keyPoint) + ';');
        statements.push(
          `MATCH (c:IntegratedChunk {id: ${toCypherString(chunk.id)}})`,
        );
        statements.push(
          `MATCH (kp:KeyPoint {id: ${toCypherString(keyPointId)}})`,
        );
        statements.push('MERGE (c)-[:HAS_KEY_POINT]->(kp);');
      }
    }
  }

  for (const trace of ir.traces) {
    statements.push(
      `MATCH (a:IntegratedChunk {id: ${toCypherString(trace.fromChunkId)}})`,
    );
    statements.push(
      `MATCH (b:IntegratedChunk {id: ${toCypherString(trace.toChunkId)}})`,
    );
    statements.push(`MERGE (a)-[r:${trace.type}]->(b)`);
    statements.push('SET r.reason = ' + toCypherString(trace.reason) + ';');
  }

  statements.push('');

  for (const link of ir.chunkTopicLinks) {
    statements.push(
      `MATCH (c:IntegratedChunk {id: ${toCypherString(link.chunkId)}})`,
    );
    statements.push(`MATCH (t:Topic {id: ${toCypherString(link.topicId)}})`);
    statements.push('MERGE (c)-[r:ABOUT]->(t)');
    statements.push('SET r.reason = ' + toCypherString(link.reason) + ';');
  }

  return statements.join('\n');
}

function buildQueryPack(ir: IntegratedIR): string {
  return [
    '// Neo4j Query Pack â€” Integrated Being IR',
    `// IR: ${ir.id}`,
    `// Generated for section: ${ir.section}`,
    '',
    '// Q1: Graph inventory by labels',
    'MATCH (n)',
    'UNWIND labels(n) AS label',
    'RETURN label, count(*) AS count',
    'ORDER BY count DESC;',
    '',
    '// Q2: Source -> Chunk chain',
    'MATCH (s:SourceText)-[:HAS_CHUNK]->(c:IntegratedChunk)',
    'RETURN s.id AS sourceId, c.id AS chunkId, c.globalOrder AS globalOrder, c.lineStart AS lineStart, c.lineEnd AS lineEnd',
    'ORDER BY c.globalOrder;',
    '',
    '// Q3: Topic hierarchy in this IR',
    `MATCH (:IntegratedIR {id: '${ir.id}'})-[:HAS_TOPIC]->(t:Topic)`,
    'OPTIONAL MATCH (p:Topic)-[:PARENT_OF]->(t)',
    'RETURN t.id AS topicId, t.name AS name, t.path AS path, t.level AS level, p.id AS parentId',
    'ORDER BY t.level, t.ordinal;',
    '',
    '// Q4: Chunk -> Topic mapping',
    `MATCH (:IntegratedIR {id: '${ir.id}'})-[:HAS_SOURCE]->(:SourceText)-[:HAS_CHUNK]->(c:IntegratedChunk)-[r:ABOUT]->(t:Topic)`,
    'RETURN c.id AS chunkId, c.globalOrder AS globalOrder, t.id AS topicId, t.name AS topicName, r.reason AS reason',
    'ORDER BY c.globalOrder, t.level;',
    '',
    '// Q4b: Chunk -> Becoming concept evidence mapping',
    `MATCH (:IntegratedIR {id: '${ir.id}'})-[:HAS_SOURCE]->(:SourceText)-[:HAS_CHUNK]->(c:IntegratedChunk)-[r:ABOUT]->(t:Topic)`,
    "WHERE t.id STARTS WITH 'topic-concept-becoming-'",
    'RETURN c.id AS chunkId, c.globalOrder AS globalOrder, t.id AS conceptId, t.name AS conceptName, r.reason AS reason',
    'ORDER BY c.globalOrder, t.name;',
    '',
    '// Q5: Trace edges inside this IR',
    `MATCH (:IntegratedIR {id: '${ir.id}'})-[:HAS_SOURCE]->(:SourceText)-[:HAS_CHUNK]->(a:IntegratedChunk)-[r:NEXT|NEGATES|SUBLATES|REFLECTS|MEDIATES]->(b:IntegratedChunk)`,
    'RETURN a.id AS fromChunk, type(r) AS rel, b.id AS toChunk, r.reason AS reason',
    'ORDER BY a.globalOrder;',
    '',
    '// Q6: Key points for one chunk (replace chunk id)',
    "MATCH (c:IntegratedChunk {id: 'being-1'})-[:HAS_KEY_POINT]->(k:KeyPoint)",
    'RETURN c.id AS chunkId, k.ordinal AS ordinal, k.text AS keyPoint',
    'ORDER BY k.ordinal;',
  ].join('\n');
}

function toPascalIdentifier(value: string): string {
  const normalized = value
    .replace(/[^a-zA-Z0-9]+/g, ' ')
    .trim()
    .split(/\s+/)
    .filter(Boolean)
    .map((part) => part[0]?.toUpperCase() + part.slice(1))
    .join('');

  if (!normalized) {
    return 'Item';
  }

  if (/^[0-9]/.test(normalized)) {
    return `N${normalized}`;
  }

  return normalized;
}

function renderIntegratedTopicMapFile(
  constName: string,
  typeName: string,
  sourcePrefix: string,
  ir: IntegratedIR,
): string {
  const sourceLines = ir.sourceDocuments.map((source) => {
    const sourceConst = `${sourcePrefix}Source${toPascalIdentifier(source.id)}`;
    return {
      sourceConst,
      line: `const ${sourceConst} = ${JSON.stringify(source, null, 2)} as const;`,
    };
  });

  const sourceDocList = sourceLines
    .map((source) => source.sourceConst)
    .join(',\n  ');

  return [
    '// Generated by src/relative/core/compiler/generate-being-ir.ts',
    '',
    ...sourceLines.map((source) => source.line),
    '',
    `const ${sourcePrefix}Sources = [`,
    `  ${sourceDocList},`,
    '] as const;',
    '',
    `const ${sourcePrefix}Traces = ${JSON.stringify(ir.traces, null, 2)} as const;`,
    '',
    `const ${sourcePrefix}Topics = ${JSON.stringify(ir.topics, null, 2)} as const;`,
    '',
    `const ${sourcePrefix}ChunkTopicLinks = ${JSON.stringify(ir.chunkTopicLinks, null, 2)} as const;`,
    '',
    `const ${sourcePrefix}Metadata = ${JSON.stringify(ir.metadata, null, 2)} as const;`,
    '',
    `export const ${constName} = {`,
    `  id: ${JSON.stringify(ir.id)},`,
    `  mode: ${JSON.stringify(ir.mode)},`,
    `  title: ${JSON.stringify(ir.title)},`,
    `  section: ${JSON.stringify(ir.section)},`,
    `  sourceDocuments: ${sourcePrefix}Sources,`,
    `  traces: ${sourcePrefix}Traces,`,
    `  topics: ${sourcePrefix}Topics,`,
    `  chunkTopicLinks: ${sourcePrefix}ChunkTopicLinks,`,
    `  metadata: ${sourcePrefix}Metadata,`,
    '} as const;',
    '',
    `export type ${typeName} = typeof ${constName};`,
    '',
  ].join('\n');
}

function renderSectionDialecticIR(
  exportName: string,
  statesExportName: string,
  ir: DialecticIR,
): string {
  const stateEntries = ir.states.map((state, index) => {
    const baseName = toPascalIdentifier(state.id);
    const constName = `state${baseName || `Index${index + 1}`}`;
    return {
      id: state.id,
      constName,
      content: `const ${constName}: DialecticState = ${JSON.stringify(state, null, 2)};`,
    };
  });

  const stateList = stateEntries
    .map((entry) => entry.constName)
    .join(',\n    ');

  const stateMapEntries = stateEntries
    .map((entry) => `  ${JSON.stringify(entry.id)}: ${entry.constName},`)
    .join('\n');

  const metadataWithoutStates: Omit<DialecticIR, 'states'> = {
    id: ir.id,
    title: ir.title,
    section: ir.section,
    metadata: ir.metadata,
  };

  return [
    "import type { DialecticIR, DialecticState } from '@schema/dialectic';",
    '',
    '// Generated by src/relative/core/compiler/generate-being-ir.ts',
    ...stateEntries.map((entry) => entry.content),
    '',
    `export const ${exportName}: DialecticIR = {`,
    `  id: ${JSON.stringify(metadataWithoutStates.id)},`,
    `  title: ${JSON.stringify(metadataWithoutStates.title)},`,
    `  section: ${JSON.stringify(metadataWithoutStates.section)},`,
    '  states: [',
    `    ${stateList},`,
    '  ],',
    `  metadata: ${JSON.stringify(metadataWithoutStates.metadata, null, 2)},`,
    '};',
    '',
    `export const ${statesExportName} = {`,
    stateMapEntries,
    '};',
    '',
  ].join('\n');
}

function buildBecomingConceptTopics(
  seeds: ConceptTopicSeed[],
  chapterParentTopicId: string,
  chapterParentPath: string,
  chapterParentLevel: number,
): IntegratedTopic[] {
  const byId = new Map(seeds.map((seed) => [seed.id, seed]));
  const siblingsByParent = new Map<string, string[]>();

  for (const seed of seeds) {
    const parentKey = seed.parentId ?? '__root__';
    const siblings = siblingsByParent.get(parentKey) ?? [];
    siblings.push(seed.id);
    siblingsByParent.set(parentKey, siblings);
  }

  const cache = new Map<string, IntegratedTopic>();

  const buildOne = (seedId: string): IntegratedTopic => {
    const existing = cache.get(seedId);
    if (existing) return existing;

    const seed = byId.get(seedId);
    if (!seed) {
      throw new Error(`Unknown Becoming concept seed: ${seedId}`);
    }

    const topicId = `topic-${seed.id}`;
    const siblingKey = seed.parentId ?? '__root__';
    const siblings = siblingsByParent.get(siblingKey) ?? [];
    const ordinal = Math.max(1, siblings.indexOf(seed.id) + 1);

    let parentTopicId = chapterParentTopicId;
    let parentPath = chapterParentPath;
    let parentLevel = chapterParentLevel;

    if (seed.parentId) {
      const parent = buildOne(seed.parentId);
      parentTopicId = parent.id;
      parentPath = parent.path;
      parentLevel = parent.level;
    }

    const topic: IntegratedTopic = {
      id: topicId,
      name: seed.name,
      level: parentLevel + 1,
      path: `${parentPath}/${seed.name}`,
      ordinal,
      parentId: parentTopicId,
    };

    cache.set(seedId, topic);
    return topic;
  };

  for (const seed of seeds) {
    buildOne(seed.id);
  }

  return seeds
    .map((seed) => cache.get(seed.id))
    .filter((topic): topic is IntegratedTopic => Boolean(topic));
}

async function main() {
  const here = path.dirname(fileURLToPath(import.meta.url));
  const packageRoot = path.resolve(here, '..', '..', '..', '..');

  const sourceSpecs: SourceSpec[] = [
    {
      id: 'source-being',
      title: 'A. BEING',
      sourceFile: 'relative/being/quality/being/sources/being.txt',
      topicMap: beingTopicMap,
    },
    {
      id: 'source-nothing',
      title: 'B. NOTHING',
      sourceFile: 'relative/being/quality/being/sources/nothing.txt',
      topicMap: nothingTopicMap,
    },
    {
      id: 'source-becoming',
      title: 'C. BECOMING',
      sourceFile: 'relative/being/quality/being/sources/becoming.txt',
      topicMap: becomingTopicMap,
    },
  ];

  let globalOrder = 1;
  const traces: IntegratedTrace[] = [];
  const sourceDocuments: IntegratedSourceDocument[] = [];

  for (const sourceSpec of sourceSpecs) {
    const sourceAbsPath = path.join(packageRoot, 'src', sourceSpec.sourceFile);
    const fullSource = await fs.readFile(sourceAbsPath, 'utf8');
    const totalLines = fullSource.split(/\r?\n/).length;

    const chunks: IntegratedChunk[] = sourceSpec.topicMap.map(
      (entry, index) => {
        const sourceText = extractChunkText(fullSource, entry.lineRange);
        const chunk: IntegratedChunk = {
          id: entry.id,
          title: entry.title,
          sourceId: sourceSpec.id,
          sourceFile: sourceSpec.sourceFile,
          lineRange: entry.lineRange,
          description: entry.description,
          keyPoints: entry.keyPoints,
          orderInSource: index + 1,
          globalOrder,
          sourceText,
          tags: [],
        };

        chunk.tags = deriveTags(chunk);
        globalOrder += 1;
        return chunk;
      },
    );

    for (let index = 0; index < chunks.length - 1; index += 1) {
      const current = chunks[index];
      const next = chunks[index + 1];
      if (!current || !next) continue;

      traces.push({
        fromChunkId: current.id,
        toChunkId: next.id,
        type: 'NEXT',
        reason: 'Sequential order in source text.',
      });
    }

    sourceDocuments.push({
      id: sourceSpec.id,
      title: sourceSpec.title,
      sourceFile: sourceSpec.sourceFile,
      totalLines,
      chunks,
    });
  }

  traces.push({
    fromChunkId: 'being-1',
    toChunkId: 'being-2',
    type: 'MEDIATES',
    reason:
      'Pure being mediates into emptiness and indeterminateness within A. Being.',
  });

  traces.push({
    fromChunkId: 'becoming-2',
    toChunkId: 'becoming-3',
    type: 'MEDIATES',
    reason:
      'Unseparatedness is developed into the two determinations of becoming.',
  });

  traces.push({
    fromChunkId: 'being-2',
    toChunkId: 'nothing-1',
    type: 'NEGATES',
    reason: 'Pure being in indeterminacy resolves into pure nothing.',
  });

  traces.push({
    fromChunkId: 'nothing-2',
    toChunkId: 'becoming-1',
    type: 'SUBLATES',
    reason: 'Identity of being and nothing transitions into becoming.',
  });

  traces.push({
    fromChunkId: 'becoming-6',
    toChunkId: 'becoming-7',
    type: 'SUBLATES',
    reason:
      'Vanishedness of becoming yields the quiescent simplicity of existence.',
  });

  const topics: IntegratedTopic[] = [
    {
      id: 'topic-being',
      name: 'Being',
      level: 0,
      path: 'Being',
      ordinal: 1,
      parentId: null,
    },
    {
      id: 'topic-being-quality',
      name: 'Quality',
      level: 1,
      path: 'Being/Quality',
      ordinal: 1,
      parentId: 'topic-being',
    },
    {
      id: 'topic-being-quantity',
      name: 'Quantity',
      level: 1,
      path: 'Being/Quantity',
      ordinal: 2,
      parentId: 'topic-being',
    },
    {
      id: 'topic-being-measure',
      name: 'Measure',
      level: 1,
      path: 'Being/Measure',
      ordinal: 3,
      parentId: 'topic-being',
    },
    {
      id: 'topic-being-quality-being-nothing-becoming',
      name: 'Being-Nothing-Becoming',
      level: 2,
      path: 'Being/Quality/Being-Nothing-Becoming',
      ordinal: 1,
      parentId: 'topic-being-quality',
    },
    {
      id: 'topic-being-quality-being',
      name: 'A. Being',
      level: 3,
      path: 'Being/Quality/Being-Nothing-Becoming/A.Being',
      ordinal: 1,
      parentId: 'topic-being-quality-being-nothing-becoming',
    },
    {
      id: 'topic-being-quality-nothing',
      name: 'B. Nothing',
      level: 3,
      path: 'Being/Quality/Being-Nothing-Becoming/B.Nothing',
      ordinal: 2,
      parentId: 'topic-being-quality-being-nothing-becoming',
    },
    {
      id: 'topic-being-quality-becoming',
      name: 'C. Becoming',
      level: 3,
      path: 'Being/Quality/Being-Nothing-Becoming/C.Becoming',
      ordinal: 3,
      parentId: 'topic-being-quality-being-nothing-becoming',
    },
  ];

  const becomingConceptIntegratedTopics = buildBecomingConceptTopics(
    becomingConceptTopics.map((seed) => ({
      id: seed.id,
      name: seed.name,
      parentId: seed.parentId,
      evidenceChunks: seed.evidenceChunks,
    })),
    'topic-being-quality-becoming',
    'Being/Quality/Being-Nothing-Becoming/C.Becoming',
    3,
  );

  topics.push(...becomingConceptIntegratedTopics);

  const sectionTopicBySourceId: Record<string, string> = {
    'source-being': 'topic-being-quality-being',
    'source-nothing': 'topic-being-quality-nothing',
    'source-becoming': 'topic-being-quality-becoming',
  };

  const chunkTopicLinks: ChunkTopicLink[] = [];

  for (const source of sourceDocuments) {
    const sectionTopicId = sectionTopicBySourceId[source.id];
    if (!sectionTopicId) continue;

    for (const chunk of source.chunks) {
      chunkTopicLinks.push({
        chunkId: chunk.id,
        topicId: sectionTopicId,
        reason: `Chunk belongs to ${source.title}.`,
      });

      chunkTopicLinks.push({
        chunkId: chunk.id,
        topicId: 'topic-being-quality-being-nothing-becoming',
        reason:
          'Chunk belongs to the Being-Nothing-Becoming integrated chapter.',
      });

      if (source.id === 'source-becoming') {
        for (const concept of becomingConceptTopics) {
          if (!concept.evidenceChunks.includes(chunk.id)) {
            continue;
          }

          chunkTopicLinks.push({
            chunkId: chunk.id,
            topicId: `topic-${concept.id}`,
            reason: `Chunk provides evidence for concept: ${concept.name}.`,
          });
        }
      }
    }
  }

  const ir: IntegratedIR = {
    id: 'integrated-being-topicmap-ir',
    mode: 'debug',
    title: 'Integrated Being TopicMap IR',
    section: 'Doctrine of Being / Quality / Being-Nothing-Becoming',
    sourceDocuments,
    traces,
    topics,
    chunkTopicLinks,
    metadata: {
      totalSources: sourceDocuments.length,
      totalChunks: sourceDocuments.reduce(
        (sum, source) => sum + source.chunks.length,
        0,
      ),
      totalTopics: topics.length,
      totalChunkTopicLinks: chunkTopicLinks.length,
      generatedAt: new Date().toISOString(),
    },
  };

  const cypher = buildCypher(ir);
  const queryPack = buildQueryPack(ir);

  const outputDir = path.join(
    packageRoot,
    'src',
    'relative',
    'being',
    'quality',
    'being',
    'sources',
    'generated',
  );

  const topLevelIrPath = path.join(
    packageRoot,
    'src',
    'relative',
    'being',
    'quality',
    'being',
    'integrated-topicmap-ir.ts',
  );

  await fs.mkdir(outputDir, { recursive: true });

  const cypherPath = path.join(outputDir, 'integrated-topicmap-ir.cypher');
  const queryPath = path.join(
    outputDir,
    'integrated-topicmap-query-pack.cypher',
  );
  const debugTsPath = path.join(outputDir, 'integrated-topicmap-ir.debug.ts');

  const debugTs = renderIntegratedTopicMapFile(
    'integratedTopicMapDebug',
    'IntegratedTopicMapDebug',
    'integratedTopicMapDebug',
    ir,
  );

  const topLevelTs = renderIntegratedTopicMapFile(
    'integratedBeingTopicMapIR',
    'IntegratedBeingTopicMapIR',
    'integratedBeingTopicMap',
    ir,
  );

  const sectionDialecticOutputs = sectionDialecticSpecs.map((spec) => {
    const parsed = DialecticIRSchema.safeParse(spec.ir);
    if (!parsed.success) {
      const issues = parsed.error.issues
        .map((issue) => `${issue.path.join('.')}: ${issue.message}`)
        .join('\n');
      throw new Error(
        `Being section DialecticIR validation failed (${spec.fileName}):\n${issues}`,
      );
    }

    const content = renderSectionDialecticIR(
      spec.exportName,
      spec.statesExportName,
      parsed.data,
    );

    const filePath = path.join(
      packageRoot,
      'src',
      'relative',
      'being',
      'quality',
      'being',
      spec.fileName,
    );

    return { filePath, content };
  });

  await fs.writeFile(cypherPath, cypher, 'utf8');
  await fs.writeFile(queryPath, queryPack, 'utf8');
  await fs.writeFile(debugTsPath, debugTs, 'utf8');
  await fs.writeFile(topLevelIrPath, topLevelTs, 'utf8');
  await Promise.all(
    sectionDialecticOutputs.map((output) =>
      fs.writeFile(output.filePath, output.content, 'utf8'),
    ),
  );

  console.log(
    `Generated ${path.relative(packageRoot, cypherPath)}, ${path.relative(packageRoot, queryPath)}, ${path.relative(packageRoot, debugTsPath)}, ${path.relative(packageRoot, topLevelIrPath)}, and ${sectionDialecticOutputs.length} section DialecticIR files.`,
  );
}

await main();
